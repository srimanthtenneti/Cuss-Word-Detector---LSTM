{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Based Cuss word detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMx7wP5SDcuLHYnZeYL6IXI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srimanthtenneti/Cuss-Word-Detector---LSTM/blob/master/LSTM_Based_Cuss_word_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5Q8lWlki2jQ",
        "colab_type": "text"
      },
      "source": [
        "# Cuss word Detector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn6ibHdii-mX",
        "colab_type": "text"
      },
      "source": [
        "This code implements a cuss word detector using some samples and an LSTM array. A total of 7 cuss words are going to be taken in various contexts and the detector is going to be implemented.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZAP4-KGjTIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as ply\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaEXVp-C3C1T",
        "colab_type": "text"
      },
      "source": [
        "# Target Words\n",
        "\n",
        "1. Fuck\n",
        "2. Bastard\n",
        "3. Dickhead\n",
        "4. Prick\n",
        "5. Pussy\n",
        "6. Fuck off\n",
        "7. Cock\n",
        "\n",
        "The above are all the cuss words that the detector aims to detect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF7Q2iUPAeeM",
        "colab_type": "text"
      },
      "source": [
        "# Data Set \n",
        "\n",
        "The dataset is a collection of certain sentences that contain abusive words and the corrosponding tags if the given word in the sentence is abusive or not.\n",
        "\n",
        "Tags : {\"O\" : 0 , \"CS\" : 1}\n",
        "\n",
        "O : OK not abusive\n",
        "\n",
        "CS : Offensive language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmHjhuUBjg3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [(\"What the fuck\".lower().split() , [\"O\",\"O\",\"CS\"]),\n",
        "        (\"The boy asked him to fuckoff\".lower().split() ,[\"O\",\"O\",\"O\",\"O\",\"O\",\"CS\"]),\n",
        "        (\"I hate that bastard\".lower().split() , [\"O\",\"O\",\"O\",\"CS\"]),\n",
        "        (\"He is a dicked\".lower().split(),[\"O\",\"O\",\"O\",\"CS\"]),\n",
        "        (\"Hey prick\".lower().split(),[\"O\",\"CS\"]),\n",
        "        (\"What a pussy you are\".lower().split() , [\"O\",\"O\",\"CS\",\"O\",\"O\"]),\n",
        "        (\"Dont be a cock\".lower().split(),[\"O\",\"O\",\"O\",\"CS\"])]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOMz3g2oBX9p",
        "colab_type": "text"
      },
      "source": [
        "# Reprasenting the data in numerical format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btJ6DE1f66xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2idx = {}\n",
        "\n",
        "for sent , tag in data:\n",
        "  for word in sent:\n",
        "    if word not in word2idx:\n",
        "      word2idx[word] = len(word2idx)\n",
        "\n",
        "tag2idx = {\"O\" : 0 , \"CS\" : 1}\n",
        "tag2rev = {0 : \"O\" , 1 : \"CS\"}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CHhaMkD7Y_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3556cc01-42ba-43b9-d1e1-a27a25043d7c"
      },
      "source": [
        "print(\"The word set is : {}\".format(word2idx))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The word set is : {'what': 0, 'the': 1, 'fuck': 2, 'boy': 3, 'asked': 4, 'him': 5, 'to': 6, 'fuckoff': 7, 'i': 8, 'hate': 9, 'that': 10, 'bastard': 11, 'he': 12, 'is': 13, 'a': 14, 'dicked': 15, 'hey': 16, 'prick': 17, 'pussy': 18, 'you': 19, 'are': 20, 'dont': 21, 'be': 22, 'cock': 23}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjaAvxxg7eF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "795777e2-74e7-4edd-987e-0b208a9c9eaa"
      },
      "source": [
        "print(\"The training data is : {}\".format(data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training data is : [(['what', 'the', 'fuck'], ['O', 'O', 'CS']), (['the', 'boy', 'asked', 'him', 'to', 'fuckoff'], ['O', 'O', 'O', 'O', 'O', 'CS']), (['i', 'hate', 'that', 'bastard'], ['O', 'O', 'O', 'CS']), (['he', 'is', 'a', 'dicked'], ['O', 'O', 'O', 'CS']), (['hey', 'prick'], ['O', 'CS']), (['what', 'a', 'pussy', 'you', 'are'], ['O', 'O', 'CS', 'O', 'O']), (['dont', 'be', 'a', 'cock'], ['O', 'O', 'O', 'CS'])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4u-kqjf7mHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequence(seq , to_idx):\n",
        "  idxs = [to_idx[word] for word in seq]\n",
        "  idxs = np.array(idxs)\n",
        "  return torch.tensor(idxs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw9hGvQr8tiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "21b9c452-ada8-4d58-a814-47d31ffb61ee"
      },
      "source": [
        "testsent = \"fuckoff boy\".lower().split()\n",
        "inp = prepare_sequence(testsent , word2idx)\n",
        "print(\"The test sentence {} is tranlated to {}\\r\\n\".format(testsent , inp))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test sentence ['fuckoff', 'boy'] is tranlated to tensor([7, 3])\r\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FjcE37-Beqw",
        "colab_type": "text"
      },
      "source": [
        "# Cuss word tagger\n",
        "\n",
        "The class below implements a LSTM tagger that tags all the cuss words in the given sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fReoINk_84r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "  def __init__(self,embedding_dim,hidden_dim,vocab_size,tagset_size):\n",
        "\n",
        "    super(LSTMTagger , self).__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.word_embedding = nn.Embedding(vocab_size , embedding_dim= embedding_dim)\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size= embedding_dim , hidden_size = hidden_dim)\n",
        "\n",
        "    self.hidden2tag = nn.Linear(hidden_dim , tagset_size)\n",
        "\n",
        "    self.hidden = self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "\n",
        "    return (torch.randn(1 , 1 , self.hidden_dim),\n",
        "           torch.randn(1 , 1 , self.hidden_dim))\n",
        "\n",
        "  def forward(self , sentence):\n",
        "\n",
        "    embeds = self.word_embedding(sentence)\n",
        "\n",
        "    lstm_out , hidden_out = self.lstm(embeds.view(len(sentence) , 1 , -1) , self.hidden) \n",
        "\n",
        "    tag_outputs = self.hidden2tag(lstm_out.view(len(sentence) , -1))\n",
        "    tag_scores = F.log_softmax(tag_outputs , dim = 1)\n",
        "\n",
        "    return tag_scores   "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKDRfcfvFHix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6\n",
        "model = LSTMTagger(EMBEDDING_DIM , HIDDEN_DIM , len(word2idx) , len(tag2idx))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters() , lr = 0.1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyDpFLfSFNXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a408d414-2f8a-47e3-a9a5-898df82d11bb"
      },
      "source": [
        "print(\"Input sent : {}\".format(inp))\n",
        "tags = model(inp)\n",
        "_,pred_tags = torch.max(tags , 1)\n",
        "print(\"Pred tag : {}\".format(pred_tags))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input sent : tensor([7, 3])\n",
            "Pred tag : tensor([0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvxDjlYUFZIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "0436acb6-403e-46b1-a836-6ca512fd9ae8"
      },
      "source": [
        "n_epochs = 300\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  epoch_loss = 0.0\n",
        "\n",
        "  for sent , tags in data:\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    input_sent = prepare_sequence(sent , word2idx)\n",
        "    tag = prepare_sequence(tags , tag2idx)\n",
        "\n",
        "    model.hidden = model.init_hidden()\n",
        "\n",
        "    output = model(input_sent)\n",
        "\n",
        "    loss = loss_function(output , tag)\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  if epoch % 20 == 19:\n",
        "    print(\"Epoch : {} , loss : {}\".format(epoch , epoch_loss / len(data)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 19 , loss : 0.5189785148416247\n",
            "Epoch : 39 , loss : 0.4222014205796378\n",
            "Epoch : 59 , loss : 0.3108013996056148\n",
            "Epoch : 79 , loss : 0.1471867822110653\n",
            "Epoch : 99 , loss : 0.08494963124394417\n",
            "Epoch : 119 , loss : 0.03300481888332537\n",
            "Epoch : 139 , loss : 0.0257016835468156\n",
            "Epoch : 159 , loss : 0.017642608111990348\n",
            "Epoch : 179 , loss : 0.008294256370780724\n",
            "Epoch : 199 , loss : 0.007141864226598825\n",
            "Epoch : 219 , loss : 0.005498719235349979\n",
            "Epoch : 239 , loss : 0.01046386590626623\n",
            "Epoch : 259 , loss : 0.004956835481737342\n",
            "Epoch : 279 , loss : 0.003309302165039948\n",
            "Epoch : 299 , loss : 0.002649571347449507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhpUMycLHPEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "80e73971-d1ae-417f-899f-59d34ff5d79d"
      },
      "source": [
        "print(\"Input sent : {}\".format(inp))\n",
        "tags = model(inp)\n",
        "_,pred_tags = torch.max(tags , 1)\n",
        "print(\"Pred tag : {}\".format(pred_tags))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input sent : tensor([7, 3])\n",
            "Pred tag : tensor([1, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHalzKbKHdTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "619cd6d4-1bcd-4976-9c0f-3ed35a0cac70"
      },
      "source": [
        "pred = np.array(pred_tags)\n",
        "pred"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT67LVnBImjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ee4a3829-8e3b-4412-f68c-8620ffcc21fe"
      },
      "source": [
        "testsent = \"You \".lower().split()\n",
        "inp = prepare_sequence(testsent , word2idx)\n",
        "\n",
        "print(\"Input sent : {}\".format(testsent))\n",
        "tags = model(inp)\n",
        "_,pred_tags = torch.max(tags , 1)\n",
        "print(\"Pred tag : {}\".format(pred_tags))\n",
        "pred = np.array(pred_tags)\n",
        "\n",
        "for i in range(len(testsent)):\n",
        "  print(\"Word : {} , Predicted tag : {}\".format(testsent[i] , tag2rev[pred[i]]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input sent : ['you', 'cock']\n",
            "Pred tag : tensor([0, 1])\n",
            "Word : you , Predicted tag : O\n",
            "Word : cock , Predicted tag : CS\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}